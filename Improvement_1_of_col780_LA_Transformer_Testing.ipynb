{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Improvement 1 of col780 LA-Transformer Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivangibithel/Computer-Vision-COL780/blob/main/Improvement_1_of_col780_LA_Transformer_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P20zT4bt6kw"
      },
      "source": [
        "Improvement1 model and code download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K6bscfgFCFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2847c6ed-8270-43aa-e396-8f025125b717"
      },
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=10gUTmF4Zea_Qv4resNJW6XAKjYjWEDR8&export=download"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=10gUTmF4Zea_Qv4resNJW6XAKjYjWEDR8\n",
            "To: /content/Improvement1.zip\n",
            "100% 1.15G/1.15G [00:11<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2BWsnSnuAUL"
      },
      "source": [
        "TEST set download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zaf6_R9vttx5"
      },
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=15PaUjDFfxidMheO6RZLz7iK-PDdtHtk0&export=download"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6_kNtKMFaeY"
      },
      "source": [
        "!unzip Improvement1.zip\n",
        "!unzip test-reid.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNyAZ3YLfkm_"
      },
      "source": [
        "%cd Improvement1/\n",
        "!unzip model.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k0tqwZFj_Uk"
      },
      "source": [
        "!pip install timm\n",
        "!pip install faiss-gpu==1.7.1  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLKL31Omn-Tl"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "import random\n",
        "import zipfile\n",
        "from itertools import chain\n",
        "import typing\n",
        "import io\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from model import ClassBlock, LATransformer, LATransformerTest\n",
        "from utils import save_network, update_summary, get_id\n",
        "from metrics import rank1, rank5, rank10, calc_map\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 2\n",
        "gamma = 0.7\n",
        "seed = 42\n",
        "\n",
        "def get_device(gpu_no):\n",
        "\tif torch.cuda.is_available():\n",
        "\t\ttorch.cuda.set_device(gpu_no)\n",
        "\t\treturn torch.device('cuda:{}'.format(gpu_no))\n",
        "\telse:\n",
        "\t\treturn torch.device('cpu')\n",
        "device = get_device(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6VW0Q2F3wMH"
      },
      "source": [
        "model_name ='vit_large_patch16_384'\n",
        "print(model_name)\n",
        "vit_large = timm.create_model(model_name, pretrained=True, num_classes=825)\n",
        "vit_large= vit_large.to(device)\n",
        "\n",
        "# Create La-Transformer\n",
        "model = LATransformerTest(vit_large, lmbd=8).to(device)\n",
        "\n",
        "# Load LA-Transformer\n",
        "name = \"la_with_lmbd_8\"\n",
        "\n",
        "modelfolder = './model'\n",
        "save_path = os.path.join(modelfolder,name,'net_best.pth')\n",
        "#save_path = \"net_best.pth\"\n",
        "model.load_state_dict(torch.load(save_path), strict=False)\n",
        "model.eval()\n",
        "\n",
        "transform_query_list = [\n",
        "    transforms.Resize((384,384), interpolation=3),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]\n",
        "transform_gallery_list = [\n",
        "    transforms.Resize(size=(384,384),interpolation=3), #Image.BICUBIC\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]\n",
        "data_transforms = {\n",
        "'query': transforms.Compose( transform_query_list ),\n",
        "'gallery': transforms.Compose(transform_gallery_list),\n",
        "}\n",
        "\n",
        "image_datasets = {}\n",
        "data_dir = \"/content/test-reid\"\n",
        "\n",
        "image_datasets['query'] = datasets.ImageFolder(os.path.join(data_dir, 'query'),\n",
        "                                          data_transforms['query'])\n",
        "image_datasets['gallery'] = datasets.ImageFolder(os.path.join(data_dir, 'gallery'),\n",
        "                                          data_transforms['gallery'])\n",
        "query_loader = DataLoader(dataset = image_datasets['query'], batch_size=batch_size, shuffle=False )\n",
        "gallery_loader = DataLoader(dataset = image_datasets['gallery'], batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class_names = image_datasets['query'].classes\n",
        "print(len(class_names))\n",
        "\n",
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "def extract_feature(model,dataloaders):\n",
        "    \n",
        "    features =  torch.FloatTensor()\n",
        "    count = 0\n",
        "    idx = 0\n",
        "    for data in (dataloaders):\n",
        "        img, label = data\n",
        "        img, label = img.to(device), label.to(device)\n",
        "\n",
        "        output = model(img)\n",
        "\n",
        "        n, c, h, w = img.size()\n",
        "        \n",
        "        count += n\n",
        "        features = torch.cat((features, output.detach().cpu()), 0)\n",
        "        idx += 1\n",
        "    return features\n",
        "\n",
        "# Extract Query Features\n",
        "query_feature= extract_feature(model, query_loader)\n",
        "\n",
        "# Extract Gallery Features\n",
        "gallery_feature = extract_feature(model, gallery_loader)\n",
        "\n",
        "# Retrieve labels\n",
        "gallery_path = image_datasets['gallery'].imgs\n",
        "query_path = image_datasets['query'].imgs\n",
        "\n",
        "def get_id(img_path):\n",
        "    camera_id = []\n",
        "    labels = []\n",
        "    for path, v in img_path:\n",
        "        # print(path)\n",
        "        label = path.split(\"/\")[-2]\n",
        "        filename = os.path.basename(path)\n",
        "        camera = filename.split('_')[0]\n",
        "        labels.append(int(label))\n",
        "        camera_id.append(int(camera))\n",
        "    return camera_id, labels\n",
        "\n",
        "gallery_cam,gallery_label = get_id(gallery_path)\n",
        "query_cam,query_label = get_id(query_path)\n",
        "\n",
        "concatenated_query_vectors = []\n",
        "for query in (query_feature):\n",
        "   \n",
        "    fnorm = torch.norm(query, p=2, dim=1, keepdim=True)*np.sqrt(14)\n",
        "   \n",
        "    query_norm = query.div(fnorm.expand_as(query))\n",
        "    \n",
        "    concatenated_query_vectors.append(query_norm.view((-1))) \n",
        "\n",
        "concatenated_gallery_vectors = []\n",
        "\n",
        "for gallery in (gallery_feature):\n",
        "    fnorm = torch.norm(gallery, p=2, dim=1, keepdim=True) *np.sqrt(14)\n",
        "   \n",
        "    gallery_norm = gallery.div(fnorm.expand_as(gallery))\n",
        "    \n",
        "    concatenated_gallery_vectors.append(gallery_norm.view((-1))) \n",
        "\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(24576)) # 24* 1024 --> 24576\n",
        "\n",
        "index.add_with_ids(np.array([t.numpy() for t in concatenated_gallery_vectors]),np.array(gallery_label))\n",
        "\n",
        "def search(query: str, k=1):\n",
        "    encoded_query = query.unsqueeze(dim=0).numpy()\n",
        "    top_k = index.search(encoded_query, k)\n",
        "    return top_k\n",
        "\n",
        "rank1_score = 0\n",
        "rank5_score = 0\n",
        "rank10_score = 0\n",
        "ap = 0\n",
        "count = 0\n",
        "for query, label in zip(concatenated_query_vectors, query_label):\n",
        "    count += 1\n",
        "    label = label\n",
        "    print(\"Query:\",count)\n",
        "    print(\"Ground Truth Label:\",label)\n",
        "    output = search(query, k=10)\n",
        "    print(\"Output:\",output[0][0])\n",
        "    print(\"Output:\",output[1][0])\n",
        "    rank1_score += rank1(label, output) \n",
        "    rank5_score += rank5(label, output) \n",
        "    rank10_score += rank10(label, output) \n",
        "    print(\"Correct: {}, Total: {}, Incorrect: {}\".format(rank1_score, count, count-rank1_score), end=\"\\r\")\n",
        "    ap += calc_map(label, output)\n",
        "    print(\"Average Precision:\", calc_map(label, output))\n",
        "    print(\"Rank-1\",rank1(label, output))\n",
        "    print(\"Rank-5\",rank5(label, output))\n",
        "    print(\" \")\n",
        "    print(\" --------------------------------------------------------------- \")\n",
        "    print(\" \")\n",
        "\n",
        "print(\"Rank1: {}, Rank5: {}, Rank10: {}, mAP: {}\".format(rank1_score/len(query_feature), \n",
        "                                                         rank5_score/len(query_feature), \n",
        "                                                         rank10_score/len(query_feature), ap/len(query_feature)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK9eIk-RBO3o"
      },
      "source": [
        "If we visually observe the Images in Query and gallery folder of 088 folder, we see that the query matches gallery image exactly and the output above shows that top 10 matches for the query number 28 having the ground truth label as 88 is all 88. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Iw731Ugwki3"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "import cv2\n",
        "# concatenated_query_vectors\n",
        "# concatenated_gallery_vectors\n",
        "for i in range(len(concatenated_query_vectors)):\n",
        "  frame = query_path[i][0]\n",
        "  img = cv2.imread(frame)\n",
        "  print(\"Query Image\")\n",
        "  plt.imshow(img)\n",
        "  plt.show()  \n",
        "  Distance_list=[]\n",
        "  for j in range(len(concatenated_gallery_vectors)):\n",
        "    dis = distance.cosine(concatenated_query_vectors[i], concatenated_gallery_vectors[j])\n",
        "    a = [j]\n",
        "    a.append(dis)\n",
        "    Distance_list.append(a)\n",
        "  Distance_list.sort(key = lambda x: x[1])\n",
        "  # print(Distance_list[:5])\n",
        "  b = Distance_list[:5]\n",
        "  print(\"Top 5 Retrieved results based on Cosine similarity\")\n",
        "  for k in b:\n",
        "    c = k[0]\n",
        "    frame = gallery_path[c][0]\n",
        "    img = cv2.imread(frame)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "  print(\" \")\n",
        "  print(\" --------------------------------------------------------------- \")\n",
        "  print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi2D4GperPrs"
      },
      "source": [
        "# fig, axs = plt.subplots(7,2,figsize=(30,30))\n",
        "# for i in range(2,9):\n",
        "#   path = \"/content/test-reid/gallery/\"\n",
        "#   p1 = path + \"113/01_\"+str(i)+\".png\" \n",
        "#   p2 = path + \"113/02_\"+str(i)+\".png\"\n",
        "#   img1 = cv2.imread(p1)\n",
        "#   img2 = cv2.imread(p2)\n",
        "#   # print(p1)\n",
        "#   axs[i-2,0].imshow(img1)\n",
        "#   # print(p2)\n",
        "#   axs[i-2,1].imshow(img2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "namqikSDiiaK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}